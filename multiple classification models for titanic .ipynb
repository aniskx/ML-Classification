{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import accuracy_score \n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import  QuadraticDiscriminantAnalysis \n",
    "from sklearn.svm import LinearSVC \n",
    "from sklearn.neighbors import RadiusNeighborsClassifier \n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked_C  Embarked_Q  \\\n",
       "0         0       2    1  30.0      0      0  13.0000           0           0   \n",
       "1         0       3    1  18.0      0      0   7.7750           0           0   \n",
       "2         0       2    1  25.0      0      0  13.0000           0           0   \n",
       "3         0       3    1   7.0      4      1  39.6875           0           0   \n",
       "4         0       3    1  39.0      1      5  31.2750           0           0   \n",
       "\n",
       "   Embarked_S  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data = pd.read_csv('titanic/titanic_processed.csv')\n",
    "titanic_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Pclass',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Fare',\n",
       " 'Embarked_C',\n",
       " 'Embarked_Q',\n",
       " 'Embarked_S']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Features = list(titanic_data.columns[1:])\n",
    "Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary that holds results ( metrics )\n",
    "# of built models\n",
    "result_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to summarize diffrent scores\n",
    "\n",
    "def summary_class(y_test,y_pred):\n",
    "    acc = accuracy_score(y_test,y_pred,normalize = True)\n",
    "    num_acc = accuracy_score(y_test,y_pred, normalize = False)\n",
    "    \n",
    "    prec = precision_score(y_test,y_pred)\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    return{'accuracy' : acc,\n",
    "           'precision' : prec,\n",
    "           'recall' : recall,\n",
    "           'accuracy_count' : num_acc,}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to build and train diffrent classification models \n",
    "# classifier_fn : a function we define that takes training data \n",
    "#                 instantiate an estimator object and trains the model \n",
    "#name_of_y_col :   name of column in our data that contains the target \n",
    "#name_of_x_cols : name of features specified in a list \n",
    "#dataset        :  data frame that holds training data \n",
    "\n",
    "def build_model (classifier_fn,\n",
    "                name_of_y_col,\n",
    "                name_of_x_cols,\n",
    "                dataset,\n",
    "                test_frac = 0.2):\n",
    "    x = dataset[name_of_x_cols]\n",
    "    y = dataset[name_of_y_col]\n",
    "    \n",
    "    x_train,x_test,y_train,y_test = train_test_split(x,y,test_size = test_frac)\n",
    "    \n",
    "    model  = classifier_fn(x_train,y_train)\n",
    "    y_pred = model.predict(x_test)\n",
    "    y_pred_train = model.predict(x_train)\n",
    "    \n",
    "    train_summary = summary_class(y_train,y_pred_train)\n",
    "    test_summary = summary_class(y_test,y_pred)\n",
    "    pred_results = pd.DataFrame({'y_test':y_test,\n",
    "                                'y_pred':y_pred})\n",
    "    \n",
    "    model_crosstab = pd.crosstab(pred_results.y_pred,pred_results.y_test)\n",
    "    return {'training': train_summary,\n",
    "            'test': test_summary,\n",
    "             'confusion_matrix': model_crosstab}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_results():\n",
    "    for key in result_dict :\n",
    "        print('classification :', key)\n",
    "        \n",
    "        print()\n",
    "        print('training data')\n",
    "        for score in result_dict[key]['training'] :\n",
    "            print(score,result_dict[key]['training'][score])\n",
    "        print()\n",
    "        print('test data')\n",
    "        for score in result_dict[key]['test']:\n",
    "            print(score, result_dict[key]['test'][score])\n",
    "            \n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic Regression\n",
    "def logistic_fn(x_train, y_train):\n",
    "    model = LogisticRegression(solver = 'liblinear')\n",
    "    model.fit(x_train,y_train)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict['model~logistic'] = build_model(logistic_fn,\n",
    "                                            'Survived',\n",
    "                                             Features,\n",
    "                                             titanic_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear discriminant Analysis \n",
    "def lda_fn(x_train, y_train, solver = 'svd'):\n",
    "    model = LinearDiscriminantAnalysis(solver = solver)\n",
    "    model.fit(x_train,y_train)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict['model~ LDA'] = build_model(lda_fn,\n",
    "                                         'Survived',\n",
    "                                        Features,\n",
    "                                        titanic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def qda_fn(x_train, y_train, solver = 'svd'):\n",
    "    model = QuadraticDiscriminantAnalysis()\n",
    "    model.fit(x_train,y_train)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict['model~ QDA'] = build_model(qda_fn,\n",
    "                                         'Survived',\n",
    "                                        Features[0:-1], # we drop one column that was OHE to avoid \"Dummy trap\"\n",
    "                                        titanic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stochastic Gradient Descent "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SGD model \n",
    "def sgd_fn(x_train, y_train, max_iter = 2000, tol =1e-3):\n",
    "    model = SGDClassifier(max_iter=max_iter,tol=tol)\n",
    "    model.fit(x_train,y_train)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict['model~ SGD'] = build_model(sgd_fn,\n",
    "                                         'Survived',\n",
    "                                        Features,\n",
    "                                        titanic_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### support vector classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_scv_fn(x_train, y_train,C =1.0, max_iter = 2000, tol =1e-3):\n",
    "    model = LinearSVC(C=C ,max_iter=max_iter,tol=tol, dual = False)\n",
    "    model.fit(x_train,y_train)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict['model~ SVC'] = build_model(linear_scv_fn,\n",
    "                                         'Survived',\n",
    "                                        Features,\n",
    "                                        titanic_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN-classifier(Redius neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Radius_neighbor_fn (x_train, y_train,radius = 40.0):\n",
    "    model = RadiusNeighborsClassifier(radius = radius)\n",
    "    model.fit(x_train,y_train)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict['model~ Radius_neighbors'] = build_model(linear_scv_fn,\n",
    "                                         'Survived',\n",
    "                                        Features,\n",
    "                                        titanic_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Decision_tree (x_train, y_train,max_depth = None, max_features = None ):\n",
    "    model = DecisionTreeClassifier(max_depth = max_depth, max_features = max_features)\n",
    "    model.fit(x_train,y_train)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict['model~ Decision Tree'] = build_model(Decision_tree,\n",
    "                                         'Survived',\n",
    "                                        Features,\n",
    "                                        titanic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Naive_Bayes (x_train, y_train,priors = None ):\n",
    "    model = GaussianNB(priors = priors)\n",
    "    model.fit(x_train,y_train)\n",
    "    return model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict['model~ Naive Bayes'] = build_model(Naive_Bayes,\n",
    "                                         'Survived',\n",
    "                                        Features,\n",
    "                                        titanic_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "classification : model~logistic\n",
      "\n",
      "training data\n",
      "accuracy 0.7943760984182777\n",
      "precision 0.7873303167420814\n",
      "recall 0.7131147540983607\n",
      "accuracy_count 452\n",
      "\n",
      "test data\n",
      "accuracy 0.7622377622377622\n",
      "precision 0.6041666666666666\n",
      "recall 0.6590909090909091\n",
      "accuracy_count 109\n",
      "\n",
      "classification : model~ LDA\n",
      "\n",
      "training data\n",
      "accuracy 0.6942003514938488\n",
      "precision 0.8085106382978723\n",
      "recall 0.3275862068965517\n",
      "accuracy_count 395\n",
      "\n",
      "test data\n",
      "accuracy 0.7272727272727273\n",
      "precision 0.84\n",
      "recall 0.375\n",
      "accuracy_count 104\n",
      "\n",
      "classification : model~ QDA\n",
      "\n",
      "training data\n",
      "accuracy 0.7943760984182777\n",
      "precision 0.7669902912621359\n",
      "recall 0.6960352422907489\n",
      "accuracy_count 452\n",
      "\n",
      "test data\n",
      "accuracy 0.7692307692307693\n",
      "precision 0.7692307692307693\n",
      "recall 0.6557377049180327\n",
      "accuracy_count 110\n",
      "\n",
      "classification : model~ SGD\n",
      "\n",
      "training data\n",
      "accuracy 0.7082601054481547\n",
      "precision 0.6024464831804281\n",
      "recall 0.8454935622317596\n",
      "accuracy_count 403\n",
      "\n",
      "test data\n",
      "accuracy 0.7062937062937062\n",
      "precision 0.5802469135802469\n",
      "recall 0.8545454545454545\n",
      "accuracy_count 101\n",
      "\n",
      "classification : model~ SVC\n",
      "\n",
      "training data\n",
      "accuracy 0.81195079086116\n",
      "precision 0.7931034482758621\n",
      "recall 0.7123893805309734\n",
      "accuracy_count 462\n",
      "\n",
      "test data\n",
      "accuracy 0.7482517482517482\n",
      "precision 0.7166666666666667\n",
      "recall 0.6935483870967742\n",
      "accuracy_count 107\n",
      "\n",
      "classification : model~ Radius_neighbors\n",
      "\n",
      "training data\n",
      "accuracy 0.984182776801406\n",
      "precision 1.0\n",
      "recall 0.961038961038961\n",
      "accuracy_count 560\n",
      "\n",
      "test data\n",
      "accuracy 0.7482517482517482\n",
      "precision 0.6779661016949152\n",
      "recall 0.7017543859649122\n",
      "accuracy_count 107\n",
      "\n",
      "classification : model~ Naive Bayes\n",
      "\n",
      "training data\n",
      "accuracy 0.7574692442882249\n",
      "precision 0.6895161290322581\n",
      "recall 0.7370689655172413\n",
      "accuracy_count 431\n",
      "\n",
      "test data\n",
      "accuracy 0.7692307692307693\n",
      "precision 0.6825396825396826\n",
      "recall 0.7678571428571429\n",
      "accuracy_count 110\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# display results of all the trained models above \n",
    "compare_results()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### using GridSearchCV on Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked_C  Embarked_Q  \\\n",
       "0         0       2    1  30.0      0      0  13.0000           0           0   \n",
       "1         0       3    1  18.0      0      0   7.7750           0           0   \n",
       "2         0       2    1  25.0      0      0  13.0000           0           0   \n",
       "3         0       3    1   7.0      4      1  39.6875           0           0   \n",
       "4         0       3    1  39.0      1      5  31.2750           0           0   \n",
       "\n",
       "   Embarked_S  \n",
       "0           1  \n",
       "1           1  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = titanic_data.drop('Survived', axis = 1)\n",
    "Y = titanic_data['Survived']\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def summary_classification (y_test, y_pres):\n",
    "    acc = accuracy_score(y_test,y_pred, normalize = True)\n",
    "    num_acc = accuracy_score(y_test,y_pred, normalize = False)\n",
    "    prec = precision_score (y_test,y_pred)\n",
    "    recall = recall_score(y_test,y_pred)\n",
    "    \n",
    "    print(\"Test data count :\", len(y_test))\n",
    "    print(\"accuracy_count:\", num_acc)\n",
    "    print(\"accuracy_score\", acc)\n",
    "    print(\"precision_score\",prec)\n",
    "    print(\"recall_score\", recall)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 4}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {'max_depth' :[2,4,5,7,9,10]}\n",
    "\n",
    "grid_search = GridSearchCV(DecisionTreeClassifier(), parameters, cv =3,return_train_score = True)\n",
    "grid_search.fit(x_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'max_depth': 2}\n",
      "Mean Test Score :  0.7908474890931032\n",
      "Rank: 3\n",
      "Parameters: {'max_depth': 4}\n",
      "Mean Test Score :  0.7944026733500418\n",
      "Rank: 1\n",
      "Parameters: {'max_depth': 5}\n",
      "Mean Test Score :  0.7943562610229277\n",
      "Rank: 2\n",
      "Parameters: {'max_depth': 7}\n",
      "Mean Test Score :  0.7785203750116031\n",
      "Rank: 4\n",
      "Parameters: {'max_depth': 9}\n",
      "Mean Test Score :  0.7539404065719856\n",
      "Rank: 5\n",
      "Parameters: {'max_depth': 10}\n",
      "Mean Test Score :  0.7451591942820013\n",
      "Rank: 6\n"
     ]
    }
   ],
   "source": [
    "# examine and compre all of the other model build wit GridSearch\n",
    "for i in range(6):\n",
    "    print('Parameters:', grid_search.cv_results_['params'][i])\n",
    "    print('Mean Test Score : ', grid_search.cv_results_['mean_test_score'][i])\n",
    "    print('Rank:', grid_search.cv_results_['rank_test_score'][i])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### building the model with the best parameters returned by gridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_model = DecisionTreeClassifier( \\\n",
    "max_depth =grid_search.best_params_['max_depth'] ).fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = DT_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data count : 143\n",
      "accuracy_count: 118\n",
      "accuracy_score 0.8251748251748252\n",
      "precision_score 0.8918918918918919\n",
      "recall_score 0.6111111111111112\n",
      "\n"
     ]
    }
   ],
   "source": [
    " summary_classification(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### hyperparameter tuning a logistic regression classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 2, 'penalty': 'l1'}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'penalty': ['l1','l2'],\n",
    "              'C':[0.1,0.4,0.8,1,2,5]}\n",
    "\n",
    "grid_search = GridSearchCV(LogisticRegression(solver = 'liblinear'),parameters,cv=3, return_train_score = True)\n",
    "grid_search.fit(x_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: {'C': 0.1, 'penalty': 'l1'}\n",
      "Mean Test Score :  0.7592128469321451\n",
      "Rank: 12\n",
      "Parameters: {'C': 0.1, 'penalty': 'l2'}\n",
      "Mean Test Score :  0.7714842662211083\n",
      "Rank: 11\n",
      "Parameters: {'C': 0.4, 'penalty': 'l1'}\n",
      "Mean Test Score :  0.785602896129212\n",
      "Rank: 3\n",
      "Parameters: {'C': 0.4, 'penalty': 'l2'}\n",
      "Mean Test Score :  0.7768124013738049\n",
      "Rank: 9\n",
      "Parameters: {'C': 0.8, 'penalty': 'l1'}\n",
      "Mean Test Score :  0.7820848417339645\n",
      "Rank: 5\n",
      "Parameters: {'C': 0.8, 'penalty': 'l2'}\n",
      "Mean Test Score :  0.7785575048732943\n",
      "Rank: 7\n",
      "Parameters: {'C': 1, 'penalty': 'l1'}\n",
      "Mean Test Score :  0.7838392276988769\n",
      "Rank: 4\n",
      "Parameters: {'C': 1, 'penalty': 'l2'}\n",
      "Mean Test Score :  0.7785575048732943\n",
      "Rank: 7\n",
      "Parameters: {'C': 2, 'penalty': 'l1'}\n",
      "Mean Test Score :  0.7873572820941241\n",
      "Rank: 1\n",
      "Parameters: {'C': 2, 'penalty': 'l2'}\n",
      "Mean Test Score :  0.7732943469785575\n",
      "Rank: 10\n",
      "Parameters: {'C': 5, 'penalty': 'l1'}\n",
      "Mean Test Score :  0.7873572820941241\n",
      "Rank: 1\n",
      "Parameters: {'C': 5, 'penalty': 'l2'}\n",
      "Mean Test Score :  0.7820848417339645\n",
      "Rank: 5\n"
     ]
    }
   ],
   "source": [
    "# examine and compre all of the other model build wit GridSearch\n",
    "for i in range(12):\n",
    "    print('Parameters:', grid_search.cv_results_['params'][i])\n",
    "    print('Mean Test Score : ', grid_search.cv_results_['mean_test_score'][i])\n",
    "    print('Rank:', grid_search.cv_results_['rank_test_score'][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR_model = LogisticRegression( solver='liblinear',\\\n",
    "penalty =grid_search.best_params_['penalty'], C = grid_search.best_params_['C']). \\\n",
    "fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = LR_model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test data count : 143\n",
      "accuracy_count: 116\n",
      "accuracy_score 0.8111888111888111\n",
      "precision_score 0.7288135593220338\n",
      "recall_score 0.7962962962962963\n",
      "\n"
     ]
    }
   ],
   "source": [
    " summary_classification(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
